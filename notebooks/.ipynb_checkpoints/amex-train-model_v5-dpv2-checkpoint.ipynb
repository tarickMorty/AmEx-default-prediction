{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.379396Z",
     "iopub.status.busy": "2022-08-07T06:08:55.378107Z",
     "iopub.status.idle": "2022-08-07T06:08:55.412431Z",
     "shell.execute_reply": "2022-08-07T06:08:55.411149Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.379267Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.415365Z",
     "iopub.status.busy": "2022-08-07T06:08:55.414595Z",
     "iopub.status.idle": "2022-08-07T06:08:58.401412Z",
     "shell.execute_reply": "2022-08-07T06:08:58.399724Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.415313Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "import math as mt\n",
    "from math import *\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "import itertools\n",
    "import scipy as sp\n",
    "\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 34+42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    input_dir = '../src/data/processed/'\n",
    "    dpv = 'v2'\n",
    "    mv = 'v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_public.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_public.parquet')\n",
    "    test['D_86_last'] = np.where(test['D_86_last']==-1, 0, test['D_86_last'])\n",
    "    dcols = [col for col in train.columns if '_isFirstEq' in col] + [col for col in train.columns if '_isLastEq' in col]\n",
    "    train = train.drop(dcols, axis=1)\n",
    "    test = test.drop(dcols, axis=1)\n",
    "    return train, test\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def amex_metric_np(preds, target):\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 1650), (924621, 1649))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "df_train, df_test = read_data()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.462180Z",
     "iopub.status.busy": "2022-08-07T06:08:58.461074Z",
     "iopub.status.idle": "2022-08-07T06:08:58.492634Z",
     "shell.execute_reply": "2022-08-07T06:08:58.491357Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.462119Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round last float features to 2 decimal place\n",
    "num_cols = list(df_train.dtypes[(df_train.dtypes == 'float32') | (df_train.dtypes == 'float64')].index)\n",
    "num_cols = [col for col in num_cols if 'last' in col]\n",
    "\n",
    "for col in num_cols:\n",
    "    df_train[col] = df_train[col].round(4)\n",
    "    df_test[col] = X_test[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats(data, feats):\n",
    "    \n",
    "    before_ = data.shape[1]\n",
    "    cols = feats\n",
    "    data['f_min']   = data[cols].fillna(0).min(axis = 1)\n",
    "    data['f_max']   = data[cols].fillna(0).max(axis = 1)\n",
    "    data['f_mean']  = data[cols].fillna(0).mean(axis = 1)\n",
    "    data['f_sd']    = data[cols].fillna(0).std(axis = 1)\n",
    "    data['f_median']= data[cols].fillna(0).median(axis = 1)\n",
    "    data['f_sum']   = data[cols].fillna(0).sum(axis = 1)\n",
    "    data['f_skew']  = data[cols].fillna(0).skew(axis = 1)\n",
    "    data['f_gtzero']  = data[cols].gt(0).sum(axis=1)\n",
    "    data['f_ltzero']  = data[cols].lt(0).sum(axis=1)\n",
    "    data['f_gtone']  = data[cols].gt(1).sum(axis=1)\n",
    "    data['f_gttwo']  = data[cols].gt(2).sum(axis=1)\n",
    "    data['f_lttwo']  = data[cols].lt(2).sum(axis=1)\n",
    "    data['f_gtfour']  = data[cols].gt(4).sum(axis=1)\n",
    "    data['f_gteight']  = data[cols].gt(8).sum(axis=1)\n",
    "    data['f_lteight']  = data[cols].lt(8).sum(axis=1)\n",
    "    data['f_gtsixteen']  = data[cols].gt(16).sum(axis=1)\n",
    "\n",
    "    after_ = data.shape[1]\n",
    "    new_cols = data.iloc[:,before_:after_].columns.tolist()\n",
    "    \n",
    "    return data, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, stat_cols = add_stats(df_train, [col for col in df_train.columns if 'last' in col \n",
    "                                           and col not in cat_features])\n",
    "df_test = add_stats(df_test, [col for col in df_train.columns if 'last' in col and col not in cat_features])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 1656), (924621, 1655))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['customer_ID'], axis=1)\n",
    "X_test = df_test.drop(['customer_ID'], axis=1)\n",
    "Y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the difference between last and mean\n",
    "num_cols = [col for col in df_train.columns if 'last' in col]\n",
    "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "    \n",
    "for col in num_cols:\n",
    "    try:\n",
    "        X_train[f'{col}_last_mean_absdiff'] = abs(X_train[f'{col}_last'] - X_train[f'{col}_mean'])\n",
    "        X_test[f'{col}_last_mean_absdiff'] = abs(X_test[f'{col}_last'] - X_test[f'{col}_mean'])\n",
    "        X_train[f'{col}_last_mean_compare'] = np.where(X_train[f'{col}_last'] \n",
    "                                                       < 0.75*X_train[f'{col}_mean'], 1, 0).astype(int)\n",
    "        X_test[f'{col}_last_mean_compare'] = np.where(X_test[f'{col}_last'] \n",
    "                                                      < 0.75*X_test[f'{col}_mean'], 1, 0).astype(int)\n",
    "        cat_features.append(f'{col}_last_mean_compare')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0:-\n",
      "X_train shape: (367130, 2008)\n",
      "X_valid shape: (91783, 2008)\n",
      "X_test shape: (924621, 2008)\n",
      "Our fold 0 CV score is 0.7919227025785858\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1:-\n",
      "X_train shape: (367130, 2008)\n",
      "X_valid shape: (91783, 2008)\n",
      "X_test shape: (924621, 2008)\n",
      "0:\tlearn: 0.6674969\ttest: 0.6674969\ttest1: 0.6674434\tbest: 0.6674434 (0)\ttotal: 553ms\tremaining: 1h 9m 9s\n",
      "500:\tlearn: 0.2164225\ttest: 0.2164241\ttest1: 0.2217016\tbest: 0.2217016 (500)\ttotal: 4m 33s\tremaining: 1h 3m 34s\n",
      "1000:\tlearn: 0.2049341\ttest: 0.2049360\ttest1: 0.2181353\tbest: 0.2181353 (1000)\ttotal: 8m 56s\tremaining: 58m 5s\n",
      "1500:\tlearn: 0.1965392\ttest: 0.1965411\ttest1: 0.2169810\tbest: 0.2169810 (1500)\ttotal: 13m 8s\tremaining: 52m 31s\n",
      "2000:\tlearn: 0.1890916\ttest: 0.1891021\ttest1: 0.2163402\tbest: 0.2163402 (2000)\ttotal: 17m 20s\tremaining: 47m 40s\n",
      "2500:\tlearn: 0.1821339\ttest: 0.1821464\ttest1: 0.2159124\tbest: 0.2159124 (2500)\ttotal: 21m 32s\tremaining: 43m 4s\n",
      "3000:\tlearn: 0.1756366\ttest: 0.1756522\ttest1: 0.2156356\tbest: 0.2156349 (2999)\ttotal: 25m 47s\tremaining: 38m 39s\n",
      "3500:\tlearn: 0.1694414\ttest: 0.1694624\ttest1: 0.2154295\tbest: 0.2154253 (3498)\ttotal: 29m 59s\tremaining: 34m 15s\n",
      "4000:\tlearn: 0.1635868\ttest: 0.1636101\ttest1: 0.2152434\tbest: 0.2152425 (3999)\ttotal: 34m 13s\tremaining: 29m 56s\n",
      "4500:\tlearn: 0.1581561\ttest: 0.1581829\ttest1: 0.2151344\tbest: 0.2151344 (4500)\ttotal: 38m 26s\tremaining: 25m 36s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.2151193153\n",
      "bestIteration = 4510\n",
      "\n",
      "Shrink model to first 4511 iterations.\n",
      "Our fold 1 CV score is 0.7988639828448891\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2:-\n",
      "X_train shape: (367130, 2008)\n",
      "X_valid shape: (91783, 2008)\n",
      "X_test shape: (924621, 2008)\n",
      "0:\tlearn: 0.6660169\ttest: 0.6660169\ttest1: 0.6660332\tbest: 0.6660332 (0)\ttotal: 540ms\tremaining: 1h 7m 30s\n",
      "500:\tlearn: 0.2162976\ttest: 0.2162982\ttest1: 0.2223512\tbest: 0.2223512 (500)\ttotal: 4m 32s\tremaining: 1h 3m 24s\n",
      "1000:\tlearn: 0.2051010\ttest: 0.2051016\ttest1: 0.2189193\tbest: 0.2189193 (1000)\ttotal: 8m 52s\tremaining: 57m 36s\n",
      "1500:\tlearn: 0.1963813\ttest: 0.1963825\ttest1: 0.2175993\tbest: 0.2175993 (1500)\ttotal: 13m 7s\tremaining: 52m 27s\n",
      "2000:\tlearn: 0.1887869\ttest: 0.1887841\ttest1: 0.2168718\tbest: 0.2168718 (2000)\ttotal: 17m 21s\tremaining: 47m 41s\n",
      "2500:\tlearn: 0.1818450\ttest: 0.1818450\ttest1: 0.2164419\tbest: 0.2164419 (2500)\ttotal: 21m 34s\tremaining: 43m 8s\n",
      "3000:\tlearn: 0.1753777\ttest: 0.1753865\ttest1: 0.2160678\tbest: 0.2160674 (2999)\ttotal: 25m 48s\tremaining: 38m 41s\n",
      "3500:\tlearn: 0.1692488\ttest: 0.1692594\ttest1: 0.2158591\tbest: 0.2158548 (3489)\ttotal: 30m 3s\tremaining: 34m 19s\n",
      "4000:\tlearn: 0.1633547\ttest: 0.1633762\ttest1: 0.2157045\tbest: 0.2157011 (3994)\ttotal: 34m 16s\tremaining: 29m 58s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.2156224342\n",
      "bestIteration = 4257\n",
      "\n",
      "Shrink model to first 4258 iterations.\n",
      "Our fold 2 CV score is 0.7972828410021686\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3:-\n",
      "X_train shape: (367131, 2008)\n",
      "X_valid shape: (91782, 2008)\n",
      "X_test shape: (924621, 2008)\n",
      "0:\tlearn: 0.6671522\ttest: 0.6671522\ttest1: 0.6672106\tbest: 0.6672106 (0)\ttotal: 580ms\tremaining: 1h 12m 29s\n",
      "500:\tlearn: 0.2158474\ttest: 0.2158466\ttest1: 0.2238969\tbest: 0.2238969 (500)\ttotal: 4m 31s\tremaining: 1h 3m 14s\n",
      "1000:\tlearn: 0.2046427\ttest: 0.2046427\ttest1: 0.2202817\tbest: 0.2202817 (1000)\ttotal: 8m 52s\tremaining: 57m 40s\n",
      "1500:\tlearn: 0.1958542\ttest: 0.1958554\ttest1: 0.2189030\tbest: 0.2189030 (1500)\ttotal: 13m 9s\tremaining: 52m 33s\n",
      "2000:\tlearn: 0.1883780\ttest: 0.1883819\ttest1: 0.2182509\tbest: 0.2182509 (2000)\ttotal: 17m 22s\tremaining: 47m 44s\n",
      "2500:\tlearn: 0.1815978\ttest: 0.1816083\ttest1: 0.2177246\tbest: 0.2177241 (2494)\ttotal: 21m 34s\tremaining: 43m 7s\n",
      "3000:\tlearn: 0.1752379\ttest: 0.1752518\ttest1: 0.2173311\tbest: 0.2173309 (2998)\ttotal: 25m 45s\tremaining: 38m 37s\n",
      "3500:\tlearn: 0.1692670\ttest: 0.1692854\ttest1: 0.2171391\tbest: 0.2171391 (3500)\ttotal: 29m 56s\tremaining: 34m 12s\n",
      "4000:\tlearn: 0.1637736\ttest: 0.1638057\ttest1: 0.2169673\tbest: 0.2169672 (3998)\ttotal: 34m 8s\tremaining: 29m 51s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.2168691274\n",
      "bestIteration = 4353\n",
      "\n",
      "Shrink model to first 4354 iterations.\n",
      "Our fold 3 CV score is 0.7947576449982383\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4:-\n",
      "X_train shape: (367131, 2008)\n",
      "X_valid shape: (91782, 2008)\n",
      "X_test shape: (924621, 2008)\n",
      "0:\tlearn: 0.6662410\ttest: 0.6662410\ttest1: 0.6662598\tbest: 0.6662598 (0)\ttotal: 603ms\tremaining: 1h 15m 22s\n",
      "500:\tlearn: 0.2159771\ttest: 0.2159799\ttest1: 0.2237656\tbest: 0.2237656 (500)\ttotal: 4m 34s\tremaining: 1h 3m 54s\n",
      "1000:\tlearn: 0.2045637\ttest: 0.2045664\ttest1: 0.2202043\tbest: 0.2202043 (1000)\ttotal: 8m 58s\tremaining: 58m 13s\n",
      "1500:\tlearn: 0.1962280\ttest: 0.1962319\ttest1: 0.2190594\tbest: 0.2190576 (1498)\ttotal: 13m 12s\tremaining: 52m 48s\n",
      "2000:\tlearn: 0.1885946\ttest: 0.1886013\ttest1: 0.2183504\tbest: 0.2183496 (1999)\ttotal: 17m 27s\tremaining: 47m 57s\n",
      "2500:\tlearn: 0.1815669\ttest: 0.1815778\ttest1: 0.2179052\tbest: 0.2179048 (2491)\ttotal: 21m 42s\tremaining: 43m 23s\n",
      "3000:\tlearn: 0.1750451\ttest: 0.1750615\ttest1: 0.2175331\tbest: 0.2175329 (2984)\ttotal: 25m 57s\tremaining: 38m 54s\n",
      "3500:\tlearn: 0.1689465\ttest: 0.1689768\ttest1: 0.2172808\tbest: 0.2172808 (3500)\ttotal: 30m 11s\tremaining: 34m 29s\n",
      "4000:\tlearn: 0.1631457\ttest: 0.1631892\ttest1: 0.2170811\tbest: 0.2170811 (4000)\ttotal: 34m 25s\tremaining: 30m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.217057052\n",
      "bestIteration = 4179\n",
      "\n",
      "Shrink model to first 4218 iterations. (min iterations for best model = 4200)\n",
      "Our fold 4 CV score is 0.7936211512090278\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'dart',\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 113,\n",
    "    'learning_rate': 0.015,\n",
    "    'feature_fraction': 0.40,\n",
    "    'bagging_freq': 8,\n",
    "    'bagging_fraction': 0.60,\n",
    "    'n_jobs': -1,\n",
    "    'min_data_in_leaf': 31,\n",
    "    'verbose': -1,\n",
    "    }\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(X_train, Y_train)):\n",
    "\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold}:-')\n",
    "    \n",
    "    x_train, x_val = X_train.drop('target', axis=1).iloc[trn_ind], X_train.drop('target', axis=1).iloc[val_ind]\n",
    "    y_train, y_val = Y_train.iloc[trn_ind], Y_train.iloc[val_ind]\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "\n",
    "    print('X_train shape:', x_train.shape)\n",
    "    print('X_valid shape:', x_val.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    if fold<=4:\n",
    "#     if fold>0:\n",
    "    \n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 500,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'../src/models/BinaryModels/lgb_{CFG.mv}_dp{CFG.dpv}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "\n",
    "    else:\n",
    "        with open(f'../src/models/BinaryModels/lgb_{CFG.mv}_dp{CFG.dpv}_fold{fold}_seed{CFG.seed}.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds CV score is 0.7952378786680088\n",
      "cb_v2_dpv25fold_seed802.csv\n"
     ]
    }
   ],
   "source": [
    "# Compute out of folds metric\n",
    "score = amex_metric(Y_train, oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "oof_filename = f'oof_{CFG.mv}_dp{CFG.dpv}{CFG.n_folds}fold_seed{CFG.seed}.csv'\n",
    "tst_filename = f'lgb_{CFG.mv}_dp{CFG.dpv}{CFG.n_folds}fold_seed{CFG.seed}.csv'\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': df_train['customer_ID'], 'target': Y_train, 'prediction': oof_predictions})\n",
    "oof_df.to_csv(oof_filename, index = False)\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': df_test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(tst_filename, index = False)\n",
    "\n",
    "print(tst_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 74.2M/74.2M [00:07<00:00, 10.6MB/s]\n",
      "Successfully submitted to American Express - Default Prediction"
     ]
    }
   ],
   "source": [
    "# !kaggle competitions submit -c amex-default-prediction -f cb_v2_dpv25fold_seed802.csv -m \"catboost with \\\n",
    "# 2008 feats CV 7952\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
