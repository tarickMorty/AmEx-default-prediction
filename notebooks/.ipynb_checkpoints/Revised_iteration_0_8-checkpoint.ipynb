{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbzevOl9KITt",
    "outputId": "35e01f65-4f8d-4390-cece-15576681cbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  1 15:46:57 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfh6rfyBKMW-",
    "outputId": "695e1b31-9a95-42b8-b241-514acf4c2380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGBM'...\n",
      "remote: Enumerating objects: 26980, done.\u001b[K\n",
      "remote: Counting objects: 100% (4103/4103), done.\u001b[K\n",
      "remote: Compressing objects: 100% (433/433), done.\u001b[K\n",
      "remote: Total 26980 (delta 3866), reused 3752 (delta 3663), pack-reused 22877\u001b[K\n",
      "Receiving objects: 100% (26980/26980), 19.38 MiB | 17.69 MiB/s, done.\n",
      "Resolving deltas: 100% (19993/19993), done.\n",
      "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
      "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
      "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
      "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
      "Cloning into '/content/LightGBM/external_libs/compute'...\n",
      "remote: Enumerating objects: 21733, done.        \n",
      "remote: Counting objects: 100% (5/5), done.        \n",
      "remote: Compressing objects: 100% (5/5), done.        \n",
      "remote: Total 21733 (delta 1), reused 2 (delta 0), pack-reused 21728        \n",
      "Receiving objects: 100% (21733/21733), 8.51 MiB | 27.84 MiB/s, done.\n",
      "Resolving deltas: 100% (17567/17567), done.\n",
      "Cloning into '/content/LightGBM/external_libs/eigen'...\n",
      "remote: Enumerating objects: 116368, done.        \n",
      "remote: Counting objects: 100% (1438/1438), done.        \n",
      "remote: Compressing objects: 100% (550/550), done.        \n",
      "remote: Total 116368 (delta 935), reused 1320 (delta 888), pack-reused 114930        \n",
      "Receiving objects: 100% (116368/116368), 103.39 MiB | 31.99 MiB/s, done.\n",
      "Resolving deltas: 100% (95741/95741), done.\n",
      "Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n",
      "remote: Enumerating objects: 726, done.        \n",
      "remote: Counting objects: 100% (125/125), done.        \n",
      "remote: Compressing objects: 100% (33/33), done.        \n",
      "remote: Total 726 (delta 98), reused 97 (delta 88), pack-reused 601        \n",
      "Receiving objects: 100% (726/726), 821.43 KiB | 11.41 MiB/s, done.\n",
      "Resolving deltas: 100% (369/369), done.\n",
      "Cloning into '/content/LightGBM/external_libs/fmt'...\n",
      "remote: Enumerating objects: 30121, done.        \n",
      "remote: Counting objects: 100% (16/16), done.        \n",
      "remote: Compressing objects: 100% (11/11), done.        \n",
      "remote: Total 30121 (delta 4), reused 12 (delta 3), pack-reused 30105        \n",
      "Receiving objects: 100% (30121/30121), 14.18 MiB | 21.32 MiB/s, done.\n",
      "Resolving deltas: 100% (20336/20336), done.\n",
      "Submodule path 'external_libs/compute': checked out '36350b7de849300bd3d72a05d8bf890ca405a014'\n",
      "Submodule path 'external_libs/eigen': checked out '3147391d946bb4b6c68edd901f2add6ac1f31f8c'\n",
      "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
      "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
      "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
      "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
      "remote: Enumerating objects: 17584, done.        \n",
      "remote: Counting objects: 100% (17584/17584), done.        \n",
      "remote: Compressing objects: 100% (3764/3764), done.        \n",
      "remote: Total 17584 (delta 13745), reused 17064 (delta 13733), pack-reused 0        \n",
      "Receiving objects: 100% (17584/17584), 10.75 MiB | 22.65 MiB/s, done.\n",
      "Resolving deltas: 100% (13745/13745), done.\n",
      "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
      "remote: Enumerating objects: 1348, done.        \n",
      "remote: Counting objects: 100% (192/192), done.        \n",
      "remote: Compressing objects: 100% (99/99), done.        \n",
      "remote: Total 1348 (delta 105), reused 156 (delta 86), pack-reused 1156        \n",
      "Receiving objects: 100% (1348/1348), 7.15 MiB | 2.34 MiB/s, done.\n",
      "Resolving deltas: 100% (877/877), done.\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
      "Submodule path 'external_libs/fmt': checked out 'b6f4ceaed0a0a24ccf575fab6c56dd50ccf6f1a9'\n",
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Looking for CL_VERSION_2_2\n",
      "-- Looking for CL_VERSION_2_2 - found\n",
      "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
      "-- OpenCL include directory: /usr/include\n",
      "-- Found Boost: /usr/include (found suitable version \"1.65.1\", minimum required is \"1.56.0\") found components: filesystem system \n",
      "-- Performing Test MM_PREFETCH\n",
      "-- Performing Test MM_PREFETCH - Success\n",
      "-- Using _mm_prefetch\n",
      "-- Performing Test MM_MALLOC\n",
      "-- Performing Test MM_MALLOC - Success\n",
      "-- Using _mm_malloc\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/LightGBM/build\n",
      "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_capi_objs.dir/src/c_api.cpp.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/cuda/cuda_score_updater.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/cuda/cuda_utils.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 21%] Built target lightgbm_capi_objs\n",
      "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_column_data.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_metadata.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_row_data.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_tree.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/dense_bin.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/multi_val_dense_bin.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/multi_val_sparse_bin.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/sparse_bin.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_best_split_finder.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_data_partition.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_histogram_constructor.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_leaf_splits.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_single_gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 92%] Built target lightgbm_objs\n",
      "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n",
      "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
      "[ 98%] Built target _lightgbm\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n",
      "[100%] Built target lightgbm\n",
      "running install\n",
      "running build\n",
      "running build_py\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/lightgbm\n",
      "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "copying lightgbm/dask.py -> build/lib/lightgbm\n",
      "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "running egg_info\n",
      "creating lightgbm.egg-info\n",
      "writing lightgbm.egg-info/PKG-INFO\n",
      "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "writing requirements to lightgbm.egg-info/requires.txt\n",
      "writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "no previously-included directories found matching 'build'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching '*.txt'\n",
      "warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "warning: no files found matching 'compile/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n",
      "warning: no files found matching '*.so' under directory 'compile'\n",
      "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n",
      "warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n",
      "warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
      "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
      "warning: no files found matching '*' under directory 'compile/include'\n",
      "warning: no files found matching '*' under directory 'compile/src'\n",
      "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
      "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
      "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "running install_lib\n",
      "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/dask.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "INFO:LightGBM:Installing lib_lightgbm from: ['/content/LightGBM/lib_lightgbm.so']\n",
      "copying /content/LightGBM/lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/compat.py to compat.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py to engine.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/callback.py to callback.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/basic.py to basic.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/dask.py to dask.cpython-37.pyc\n",
      "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n",
      "running install_egg_info\n",
      "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.3.2.99-py3.7.egg-info\n",
      "running install_scripts\n"
     ]
    }
   ],
   "source": [
    "# ! git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "# ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CY87ideVKO0b",
    "outputId": "11e49eda-4c38-4118-947a-24fa63dd4436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_1VFG88Wd53"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f8dcn7YTy0J",
    "outputId": "fe190fb3-7421-40ce-904c-36f94b757f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [01:35<00:00,  5.47it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 137.71it/s]\n",
      "100%|██████████| 458913/458913 [11:19<00:00, 675.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [03:25<00:00,  2.54it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 64.68it/s]\n",
      "100%|██████████| 924621/924621 [23:01<00:00, 669.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2889)\n",
      "(924621, 2888)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last','quantile'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    for col in train_num_agg:\n",
    "        if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
    "            train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
    "            train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    train_labels = pd.read_csv('/content/drive/MyDrive/Amex Kaggle/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train1 = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    num_features.append('customer_ID')\n",
    "    cat_features.append('customer_ID')\n",
    "    train_num_agg = train[num_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg(['mean', 'min', 'max', 'std','quantile'])\n",
    "    train_num_agg.columns = ['_L3M'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train[cat_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg([ 'min', 'max'])\n",
    "    train_cat_agg.columns = ['_L3M'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "    num_features.remove('customer_ID')\n",
    "    cat_features.remove('customer_ID')\n",
    "    train2 = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg\n",
    "    train = train1.merge(train2, how = 'left', on = 'customer_ID')\n",
    "    gc.collect()\n",
    "\n",
    "    train_slope=pd.read_csv('/content/drive/MyDrive/Amex Kaggle/Derived Features/cust_id_wise_slope.csv')\n",
    "    train=train.merge(train_slope,how='left',on='customer_ID')\n",
    "\n",
    "\n",
    "\n",
    "    # Test FE\n",
    "    test = pd.read_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/test.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last','quantile'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    for col in test_num_agg:\n",
    "        if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
    "            test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
    "            test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test1 = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "\n",
    "    num_features.append('customer_ID')\n",
    "    cat_features.append('customer_ID')\n",
    "    test_num_agg = test[num_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg(['mean', 'min', 'max', 'std','quantile'])\n",
    "    test_num_agg.columns = ['_L3M'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test[cat_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg([ 'min', 'max'])\n",
    "    test_cat_agg.columns = ['_L3M'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "    num_features.remove('customer_ID')\n",
    "    cat_features.remove('customer_ID')\n",
    "    test2 = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg\n",
    "    test = test1.merge(test2, how = 'left', on = 'customer_ID')\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    test_slope=pd.read_csv('/content/drive/MyDrive/Amex Kaggle/Derived Features/cust_id_wise_slope_test.csv')\n",
    "    test=test.merge(test_slope,how='left',on='customer_ID')\n",
    "\n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    # train = reduce_mem_usage(train)\n",
    "    # test = reduce_mem_usage(test)\n",
    "    train.to_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/train_fe_plus_plus1.parquet')\n",
    "    test.to_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/test_fe_plus_plus1.parquet')\n",
    "    \n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcIpescOlZaX"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "class CFG:\n",
    "    seed = 13\n",
    "    n_folds = 10\n",
    "    target = 'target'\n",
    "    input_dir = '/content/data/'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def read_data():\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    train = pd.read_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/train_fe_plus_plus1.parquet')\n",
    "    # cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    # train=train[cat_features]\n",
    "    # test = pd.read_parquet('/content/drive/MyDrive/Amex Kaggle/Derived Features/test_fe_plus_plus1.parquet')\n",
    "    # del test['customer_ID']\n",
    "    # gc.collect()\n",
    "    return train\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def amex_metric_np(preds, target):\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IA40tLqm3HM"
   },
   "outputs": [],
   "source": [
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_0'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_1'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_2'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_3'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_4'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_5'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_6'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_7'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_8'\n",
    "# !mkdir '/content/drive/MyDrive/LGBModels_dart6/fold_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqxkjM1Nluk5",
    "outputId": "1193908e-e9d7-4e8b-a7f8-aa3842bcdf0f"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3233/3233 [11:55<00:00,  4.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 3960 features...\n",
      "[LightGBM] [Info] Number of positive: 106946, number of negative: 306076\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 12.972643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631981\n",
      "[LightGBM] [Info] Number of data points in the train set: 413022, number of used features: 3943\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051509\n",
      "[LightGBM] [Info] Start training from score -1.051509\n",
      "iteration 0, score= 0.69055\n",
      "iteration 100, score= 0.75980\n",
      "iteration 200, score= 0.76070\n",
      "iteration 300, score= 0.76305\n",
      "iteration 400, score= 0.76548\n",
      "iteration 500, score= 0.76636\n",
      "iteration 600, score= 0.76911\n",
      "iteration 700, score= 0.77116\n",
      "iteration 800, score= 0.77289\n",
      "iteration 900, score= 0.77500\n",
      "iteration 1000, score= 0.77827\n",
      "iteration 1100, score= 0.78059\n",
      "iteration 1200, score= 0.78157\n",
      "iteration 1300, score= 0.78346\n",
      "iteration 1400, score= 0.78377\n",
      "iteration 1500, score= 0.78540\n",
      "iteration 1600, score= 0.78601\n",
      "iteration 1700, score= 0.78825\n",
      "iteration 1800, score= 0.78970\n",
      "iteration 1900, score= 0.78994\n",
      "iteration 2000, score= 0.79090\n",
      "iteration 2100, score= 0.79165\n",
      "iteration 2200, score= 0.79211\n",
      "iteration 2300, score= 0.79251\n",
      "iteration 2400, score= 0.79329\n",
      "iteration 2500, score= 0.79391\n",
      "iteration 2600, score= 0.79404\n",
      "iteration 2700, score= 0.79399\n",
      "iteration 2800, score= 0.79393\n",
      "iteration 2900, score= 0.79448\n",
      "iteration 3000, score= 0.79475\n",
      "iteration 3100, score= 0.79471\n",
      "iteration 3200, score= 0.79544\n",
      "iteration 3300, score= 0.79566\n",
      "iteration 3400, score= 0.79583\n",
      "iteration 3500, score= 0.79612\n",
      "iteration 3600, score= 0.79700\n",
      "iteration 3700, score= 0.79698\n",
      "iteration 3800, score= 0.79719\n",
      "iteration 3900, score= 0.79708\n",
      "iteration 4000, score= 0.79771\n",
      "iteration 4100, score= 0.79849\n",
      "iteration 4200, score= 0.79849\n",
      "iteration 4300, score= 0.79855\n",
      "iteration 4400, score= 0.79780\n",
      "iteration 4500, score= 0.79795\n",
      "iteration 4600, score= 0.79803\n",
      "iteration 4700, score= 0.79780\n",
      "iteration 4800, score= 0.79815\n",
      "iteration 4900, score= 0.79740\n",
      "iteration 5000, score= 0.79875\n",
      "iteration 5100, score= 0.79820\n",
      "iteration 5200, score= 0.79846\n",
      "iteration 5300, score= 0.79823\n",
      "iteration 5400, score= 0.79816\n",
      "iteration 5500, score= 0.79754\n",
      "iteration 5600, score= 0.79805\n",
      "iteration 5700, score= 0.79797\n",
      "iteration 5800, score= 0.79781\n",
      "iteration 5900, score= 0.79817\n",
      "iteration 6000, score= 0.79839\n",
      "iteration 6100, score= 0.79822\n",
      "iteration 6200, score= 0.79764\n",
      "iteration 6300, score= 0.79783\n",
      "iteration 6400, score= 0.79750\n",
      "iteration 6500, score= 0.79789\n",
      "iteration 6600, score= 0.79790\n",
      "iteration 6700, score= 0.79922\n",
      "iteration 6800, score= 0.79901\n",
      "iteration 6900, score= 0.79922\n",
      "iteration 7000, score= 0.79894\n",
      "iteration 7100, score= 0.79902\n",
      "iteration 7200, score= 0.79955\n",
      "iteration 7300, score= 0.79989\n",
      "iteration 7400, score= 0.80011\n",
      "iteration 7500, score= 0.79995\n",
      "iteration 7600, score= 0.80009\n",
      "iteration 7700, score= 0.79977\n",
      "iteration 7800, score= 0.79956\n",
      "iteration 7900, score= 0.79918\n",
      "iteration 8000, score= 0.79982\n",
      "iteration 8100, score= 0.80054\n",
      "iteration 8200, score= 0.80067\n",
      "iteration 8300, score= 0.80029\n",
      "iteration 8400, score= 0.80059\n",
      "iteration 8500, score= 0.80001\n",
      "iteration 8600, score= 0.80043\n",
      "iteration 8700, score= 0.80076\n",
      "iteration 8800, score= 0.80006\n",
      "iteration 8900, score= 0.80010\n",
      "iteration 9000, score= 0.79967\n",
      "iteration 9100, score= 0.79933\n",
      "iteration 9200, score= 0.80036\n",
      "iteration 9300, score= 0.80007\n",
      "iteration 9400, score= 0.79934\n",
      "iteration 9500, score= 0.79892\n",
      "iteration 9600, score= 0.79935\n",
      "iteration 9700, score= 0.79940\n",
      "iteration 9800, score= 0.79961\n",
      "iteration 9900, score= 0.80012\n",
      "iteration 10000, score= 0.79966\n",
      "iteration 10100, score= 0.79992\n",
      "iteration 10200, score= 0.79966\n",
      "iteration 10300, score= 0.79962\n",
      "iteration 10400, score= 0.79937\n",
      "iteration 10500, score= 0.79970\n",
      "iteration 10600, score= 0.80055\n",
      "iteration 10700, score= 0.79983\n",
      "iteration 10800, score= 0.79962\n",
      "iteration 10900, score= 0.79924\n",
      "iteration 11000, score= 0.79957\n",
      "iteration 11100, score= 0.79936\n",
      "iteration 11200, score= 0.79937\n",
      "iteration 11300, score= 0.79912\n",
      "iteration 11400, score= 0.79928\n",
      "iteration 11500, score= 0.79982\n",
      "iteration 11600, score= 0.80004\n",
      "iteration 11700, score= 0.79946\n",
      "iteration 11800, score= 0.80018\n",
      "iteration 11900, score= 0.79972\n",
      "iteration 12000, score= 0.79954\n",
      "iteration 12100, score= 0.79916\n",
      "iteration 12200, score= 0.79895\n",
      "iteration 12300, score= 0.79903\n",
      "iteration 12400, score= 0.79936\n",
      "iteration 12500, score= 0.79875\n",
      "iteration 12600, score= 0.79863\n",
      "iteration 12700, score= 0.79935\n",
      "iteration 12800, score= 0.79964\n",
      "iteration 12900, score= 0.79971\n",
      "iteration 13000, score= 0.79929\n",
      "iteration 13100, score= 0.79933\n",
      "iteration 13200, score= 0.79933\n",
      "iteration 13300, score= 0.79954\n",
      "iteration 13400, score= 0.79916\n",
      "iteration 13500, score= 0.79949\n",
      "iteration 13600, score= 0.79941\n",
      "iteration 13700, score= 0.79933\n",
      "iteration 13800, score= 0.79903\n",
      "iteration 13900, score= 0.79891\n",
      "iteration 14000, score= 0.79907\n",
      "iteration 14100, score= 0.79966\n",
      "iteration 14200, score= 0.79959\n",
      "iteration 14300, score= 0.79972\n",
      "iteration 14400, score= 0.79996\n",
      "iteration 14500, score= 0.79957\n",
      "iteration 14600, score= 0.79969\n",
      "iteration 14700, score= 0.79980\n",
      "iteration 14800, score= 0.79980\n",
      "iteration 14900, score= 0.79955\n",
      "                Variables  Importance\n",
      "5                P_2_last        3966\n",
      "12              D_39_last        2497\n",
      "79                B_4_std        2480\n",
      "2894  D_39_last_mean_diff        2386\n",
      "36               S_3_mean        2381\n",
      "1804           P_2_L3Mmin        2355\n",
      "2954   B_4_last_mean_diff        2283\n",
      "40               S_3_last        2268\n",
      "1643           D_48_diff1        2268\n",
      "19               B_1_last        2223\n",
      "68              D_43_last        2192\n",
      "56             D_42_first        2183\n",
      "62          D_42_quantile        2132\n",
      "222             B_11_last        2118\n",
      "1848         D_43_L3Mmean        2108\n",
      "82               B_4_last        2107\n",
      "1810          D_39_L3Mmax        2102\n",
      "54               B_3_last        2086\n",
      "1803          P_2_L3Mmean        2058\n",
      "57              D_42_mean        2053\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 5 with 3960 features...\n",
      "[LightGBM] [Info] Number of positive: 106945, number of negative: 306077\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 12.550775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631916\n",
      "[LightGBM] [Info] Number of data points in the train set: 413022, number of used features: 3943\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051522\n",
      "[LightGBM] [Info] Start training from score -1.051522\n",
      "iteration 0, score= 0.69791\n",
      "iteration 100, score= 0.75697\n",
      "iteration 200, score= 0.75940\n",
      "iteration 300, score= 0.76105\n",
      "iteration 400, score= 0.76339\n",
      "iteration 500, score= 0.76657\n",
      "iteration 600, score= 0.76870\n",
      "iteration 700, score= 0.77026\n",
      "iteration 800, score= 0.77272\n",
      "iteration 900, score= 0.77462\n",
      "iteration 1000, score= 0.77574\n",
      "iteration 1100, score= 0.77791\n",
      "iteration 1200, score= 0.77923\n",
      "iteration 1300, score= 0.78142\n",
      "iteration 1400, score= 0.78240\n",
      "iteration 1500, score= 0.78406\n",
      "iteration 1600, score= 0.78477\n",
      "iteration 1700, score= 0.78639\n",
      "iteration 1800, score= 0.78692\n",
      "iteration 1900, score= 0.78730\n",
      "iteration 2000, score= 0.78815\n",
      "iteration 2100, score= 0.78807\n",
      "iteration 2200, score= 0.78836\n",
      "iteration 2300, score= 0.78928\n",
      "iteration 2400, score= 0.78900\n",
      "iteration 2500, score= 0.79022\n",
      "iteration 2600, score= 0.79034\n",
      "iteration 2700, score= 0.79096\n",
      "iteration 2800, score= 0.79124\n",
      "iteration 2900, score= 0.79151\n",
      "iteration 3000, score= 0.79174\n",
      "iteration 3100, score= 0.79150\n",
      "iteration 3200, score= 0.79253\n",
      "iteration 3300, score= 0.79220\n",
      "iteration 3400, score= 0.79347\n",
      "iteration 3500, score= 0.79337\n",
      "iteration 3600, score= 0.79309\n",
      "iteration 3700, score= 0.79350\n",
      "iteration 3800, score= 0.79396\n",
      "iteration 3900, score= 0.79336\n",
      "iteration 4000, score= 0.79350\n",
      "iteration 4100, score= 0.79405\n",
      "iteration 4200, score= 0.79365\n",
      "iteration 4300, score= 0.79418\n",
      "iteration 4400, score= 0.79420\n",
      "iteration 4500, score= 0.79367\n",
      "iteration 4600, score= 0.79398\n",
      "iteration 4700, score= 0.79369\n",
      "iteration 4800, score= 0.79353\n",
      "iteration 4900, score= 0.79334\n",
      "iteration 5000, score= 0.79363\n",
      "iteration 5100, score= 0.79399\n",
      "iteration 5200, score= 0.79397\n",
      "iteration 5300, score= 0.79385\n",
      "iteration 5400, score= 0.79412\n",
      "iteration 5500, score= 0.79385\n",
      "iteration 5600, score= 0.79347\n",
      "iteration 5700, score= 0.79405\n",
      "iteration 5800, score= 0.79471\n",
      "iteration 5900, score= 0.79454\n",
      "iteration 6000, score= 0.79455\n",
      "iteration 6100, score= 0.79461\n",
      "iteration 6200, score= 0.79403\n",
      "iteration 6300, score= 0.79471\n",
      "iteration 6400, score= 0.79455\n",
      "iteration 6500, score= 0.79448\n",
      "iteration 6600, score= 0.79330\n",
      "iteration 6700, score= 0.79424\n",
      "iteration 6800, score= 0.79428\n",
      "iteration 6900, score= 0.79432\n",
      "iteration 7000, score= 0.79426\n",
      "iteration 7100, score= 0.79417\n",
      "iteration 7200, score= 0.79414\n",
      "iteration 7300, score= 0.79347\n",
      "iteration 7400, score= 0.79444\n",
      "iteration 7500, score= 0.79458\n",
      "iteration 7600, score= 0.79518\n",
      "iteration 7700, score= 0.79520\n",
      "iteration 7800, score= 0.79563\n",
      "iteration 7900, score= 0.79567\n",
      "iteration 8000, score= 0.79632\n",
      "iteration 8100, score= 0.79581\n",
      "iteration 8200, score= 0.79540\n",
      "iteration 8300, score= 0.79532\n",
      "iteration 8400, score= 0.79474\n",
      "iteration 8500, score= 0.79537\n",
      "iteration 8600, score= 0.79474\n",
      "iteration 8700, score= 0.79479\n",
      "iteration 8800, score= 0.79504\n",
      "iteration 8900, score= 0.79491\n",
      "iteration 9000, score= 0.79461\n",
      "iteration 9100, score= 0.79483\n",
      "iteration 9200, score= 0.79516\n",
      "iteration 9300, score= 0.79499\n",
      "iteration 9400, score= 0.79490\n",
      "iteration 9500, score= 0.79465\n",
      "iteration 9600, score= 0.79503\n",
      "iteration 9700, score= 0.79469\n",
      "iteration 9800, score= 0.79523\n",
      "iteration 9900, score= 0.79519\n",
      "iteration 10000, score= 0.79518\n",
      "iteration 10100, score= 0.79509\n",
      "iteration 10200, score= 0.79505\n",
      "iteration 10300, score= 0.79446\n",
      "iteration 10400, score= 0.79437\n",
      "iteration 10500, score= 0.79446\n",
      "iteration 10600, score= 0.79440\n",
      "iteration 10700, score= 0.79444\n",
      "iteration 10800, score= 0.79415\n",
      "iteration 10900, score= 0.79440\n",
      "iteration 11000, score= 0.79435\n",
      "iteration 11100, score= 0.79447\n",
      "iteration 11200, score= 0.79451\n",
      "iteration 11300, score= 0.79476\n",
      "iteration 11400, score= 0.79471\n",
      "iteration 11500, score= 0.79437\n",
      "iteration 11600, score= 0.79424\n",
      "iteration 11700, score= 0.79465\n",
      "iteration 11800, score= 0.79443\n",
      "iteration 11900, score= 0.79447\n",
      "iteration 12000, score= 0.79430\n",
      "iteration 12100, score= 0.79494\n",
      "iteration 12200, score= 0.79440\n",
      "iteration 12300, score= 0.79435\n",
      "iteration 12400, score= 0.79426\n",
      "iteration 12500, score= 0.79409\n",
      "iteration 12600, score= 0.79421\n",
      "iteration 12700, score= 0.79409\n",
      "iteration 12800, score= 0.79358\n",
      "iteration 12900, score= 0.79388\n",
      "iteration 13000, score= 0.79409\n",
      "iteration 13100, score= 0.79410\n",
      "iteration 13200, score= 0.79507\n",
      "iteration 13300, score= 0.79447\n",
      "iteration 13400, score= 0.79467\n",
      "iteration 13500, score= 0.79467\n",
      "iteration 13600, score= 0.79484\n",
      "iteration 13700, score= 0.79450\n",
      "iteration 13800, score= 0.79443\n",
      "iteration 13900, score= 0.79431\n",
      "iteration 14000, score= 0.79448\n",
      "iteration 14100, score= 0.79411\n",
      "iteration 14200, score= 0.79352\n",
      "iteration 14300, score= 0.79453\n",
      "iteration 14400, score= 0.79473\n",
      "iteration 14500, score= 0.79435\n",
      "iteration 14600, score= 0.79447\n",
      "iteration 14700, score= 0.79460\n",
      "iteration 14800, score= 0.79444\n",
      "iteration 14900, score= 0.79431\n",
      "                Variables  Importance\n",
      "5                P_2_last        3939\n",
      "12              D_39_last        2624\n",
      "1804           P_2_L3Mmin        2502\n",
      "79                B_4_std        2494\n",
      "36               S_3_mean        2436\n",
      "2894  D_39_last_mean_diff        2430\n",
      "2954   B_4_last_mean_diff        2366\n",
      "82               B_4_last        2269\n",
      "222             B_11_last        2227\n",
      "1643           D_48_diff1        2221\n",
      "19               B_1_last        2221\n",
      "56             D_42_first        2168\n",
      "40               S_3_last        2154\n",
      "1803          P_2_L3Mmean        2153\n",
      "62          D_42_quantile        2105\n",
      "1848         D_43_L3Mmean        2073\n",
      "68              D_43_last        2065\n",
      "1850          D_43_L3Mmax        2045\n",
      "54               B_3_last        2013\n",
      "57              D_42_mean        2008\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "def train_and_evaluate(train):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        # test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    # num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    # num_cols = [col for col in num_cols if 'last' in col]\n",
    "    # for col in num_cols:\n",
    "    #     train[col + '_round2'] = train[col].round(2)\n",
    "        # test[col + '_round2'] = test[col].round(2)\n",
    "    # Get the difference between last and mean\n",
    "    num_cols = [col for col in train.columns if 'last' in col]\n",
    "    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            train[f'{col}_last_first_R'] = train[f'{col}_last']/train[f'{col}_first']\n",
    "            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "            train[f'{col}_last_mean_R'] = train[f'{col}_last']/train[f'{col}_mean']\n",
    "            train[f'{col}_last_max_diff'] = train[f'{col}_last'] - train[f'{col}_max']\n",
    "            train[f'{col}_last_max_R'] = train[f'{col}_last']/train[f'{col}_max']\n",
    "            train[f'{col}_max_mean_R'] = train[f'{col}_max']/train[f'{col}_mean']\n",
    "            # test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "        except:\n",
    "            pass\n",
    "    # Transform float64 and float32 to float16\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    for col in tqdm(num_cols):\n",
    "        train[col] = train[col].astype(np.float16)\n",
    "        # test[col] = test[col].astype(np.float16)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"amex_metric\",\n",
    "        'boosting': 'dart',\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40\n",
    "        }\n",
    "    # Create a numpy array to store test predictions\n",
    "    # test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    # oof_predictions = np.zeros(len(train))\n",
    "    # train=reduce_mem_usage(train)\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "      if fold in [4,5]:\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        global max_score \n",
    "        max_score = 0.75\n",
    "        def save_model():\n",
    "          def callback(env):\n",
    "              global max_score\n",
    "              iteration = env.iteration\n",
    "              score = env.evaluation_result_list[0][2]\n",
    "              if iteration % 100 == 0:\n",
    "                    print('iteration {}, score= {:.05f}'.format(iteration,score))\n",
    "              if score > max_score:\n",
    "                    max_score = score\n",
    "                    path = f'/content/drive/MyDrive/LGBModels_dart7/fold_{fold}'\n",
    "                    for fname in os.listdir(path):\n",
    "                          if fname.endswith(\".pkl\"):\n",
    "                            os.remove(os.path.join(path, fname))\n",
    "                    # print('High Score: iteration {}, score={:.05f}'.format(iteration, score))\n",
    "                    joblib.dump(env.model,os.path.join(path,f\"{score}.pkl\"))\n",
    "          callback.order = 0\n",
    "          return callback\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 15000,\n",
    "            valid_sets = [lgb_valid],\n",
    "            # early_stopping_rounds = 2000,\n",
    "            # verbose_eval = 500,\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[save_model()]\n",
    "            )\n",
    "        feat_imp=pd.DataFrame({'Variables':features,'Importance':model.feature_importance()})\n",
    "        feat_imp=feat_imp.sort_values(by='Importance',ascending=False)\n",
    "        print(feat_imp.head(20))\n",
    "        # Save best model\n",
    "        # joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # # Predict validation\n",
    "        # val_pred = model.predict(x_val)\n",
    "        # # Add to out of folds array\n",
    "        # oof_predictions[val_ind] = val_pred\n",
    "        # # Predict the test set\n",
    "        # test_pred = model.predict(test[features])\n",
    "        # test_predictions += test_pred / CFG.n_folds\n",
    "        # # Compute fold metric\n",
    "        # score = amex_metric(y_val, val_pred)\n",
    "        # print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    # Compute out of folds metric\n",
    "    # score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    # print(f'Our out of folds CV score is {score}')\n",
    "    # # Create a dataframe to store out of folds predictions\n",
    "    # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    # oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # # Create a dataframe to store test prediction\n",
    "    # test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    # test_df.to_csv(f'test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "train = read_data()\n",
    "train_and_evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgoJdOailZW1"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf-fFsyIaEWX"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Revised_iteration_0_8.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
