{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.379396Z",
     "iopub.status.busy": "2022-08-07T06:08:55.378107Z",
     "iopub.status.idle": "2022-08-07T06:08:55.412431Z",
     "shell.execute_reply": "2022-08-07T06:08:55.411149Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.379267Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.415365Z",
     "iopub.status.busy": "2022-08-07T06:08:55.414595Z",
     "iopub.status.idle": "2022-08-07T06:08:58.401412Z",
     "shell.execute_reply": "2022-08-07T06:08:58.399724Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.415313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math as mt\n",
    "from math import *\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "import itertools\n",
    "import scipy as sp\n",
    "\n",
    "from itertools import combinations\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.404961Z",
     "iopub.status.busy": "2022-08-07T06:08:58.403601Z",
     "iopub.status.idle": "2022-08-07T06:08:58.411889Z",
     "shell.execute_reply": "2022-08-07T06:08:58.410435Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.404897Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.420484Z",
     "iopub.status.busy": "2022-08-07T06:08:58.418976Z",
     "iopub.status.idle": "2022-08-07T06:08:58.432872Z",
     "shell.execute_reply": "2022-08-07T06:08:58.431062Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.420405Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_feats = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "# # D_* = Delinquency variables\n",
    "# # S_* = Spend variables\n",
    "# # P_* = Payment variables\n",
    "# # B_* = Balance variables\n",
    "# # R_* = Risk variables\n",
    "\n",
    "# D_feats = [col for col in df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'].columns if 'D_' in col]\n",
    "# S_feats = [col for col in df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'].columns if 'S_' in col]\n",
    "# P_feats = [col for col in df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'].columns if 'P_' in col]\n",
    "# B_feats = [col for col in df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'].columns if 'B_' in col]\n",
    "# R_feats = [col for col in df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'].columns if 'R_' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.436347Z",
     "iopub.status.busy": "2022-08-07T06:08:58.435364Z",
     "iopub.status.idle": "2022-08-07T06:08:58.446743Z",
     "shell.execute_reply": "2022-08-07T06:08:58.445155Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.436287Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(D_feats), len(S_feats), len(P_feats), len(B_feats), len(R_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.450691Z",
     "iopub.status.busy": "2022-08-07T06:08:58.449231Z",
     "iopub.status.idle": "2022-08-07T06:08:58.458433Z",
     "shell.execute_reply": "2022-08-07T06:08:58.456954Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.450625Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train[df_train.customer_ID=='0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'][P_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.462180Z",
     "iopub.status.busy": "2022-08-07T06:08:58.461074Z",
     "iopub.status.idle": "2022-08-07T06:08:58.492634Z",
     "shell.execute_reply": "2022-08-07T06:08:58.491357Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.462119Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n",
    "\n",
    "more_cats = ['S_8','S_11','S_13','S_15','B_4','B_16','B_19','B_20','B_22','B_33','B_41','R_3','R_5','R_8',\n",
    "             'R_9','R_10','R_11','R_13','R_16','R_17','R_18','R_20','R_26','R_9','D_39','D_44','D_49','D_51',\n",
    "             'D_59','D_70','D_72','D_74','D_75','D_78','D_79','D_80','D_81','D_82','D_83','D_84','D_89',\n",
    "             'D_91','D_92','D_103','D_106','D_107','D_108','D_109','D_111','D_113','D_122','D_123','D_123',\n",
    "             'D_124','D_125','D_129','D_135','D_136','D_137','D_138','D_139','D_140','D_143','D_145']\n",
    "\n",
    "binary_cats = ['S_6','S_18','S_20','B_31','B_32','R_2','R_4','R_15','R_19','R_21','R_22','R_23','R_24','R_25','R_28',\n",
    "              'D_86','D_87','D_93','D_94','D_96','D_127']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.494559Z",
     "iopub.status.busy": "2022-08-07T06:08:58.494203Z",
     "iopub.status.idle": "2022-08-07T06:08:58.505915Z",
     "shell.execute_reply": "2022-08-07T06:08:58.504694Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.494527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 64, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols), len(more_cats), len(binary_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.508646Z",
     "iopub.status.busy": "2022-08-07T06:08:58.508090Z",
     "iopub.status.idle": "2022-08-07T06:08:58.520078Z",
     "shell.execute_reply": "2022-08-07T06:08:58.518415Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.508612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cat_feats = cat_cols + more_cats + binary_cats\n",
    "cat_feats = cat_cols + binary_cats\n",
    "len(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.524565Z",
     "iopub.status.busy": "2022-08-07T06:08:58.523745Z",
     "iopub.status.idle": "2022-08-07T06:08:58.532931Z",
     "shell.execute_reply": "2022-08-07T06:08:58.531747Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.524529Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.536493Z",
     "iopub.status.busy": "2022-08-07T06:08:58.535785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 282/282 [01:00<00:00,  4.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 497.49it/s]\n",
      "100%|███████████████████████████████████████████████████████| 458913/458913 [12:38<00:00, 605.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 282/282 [02:01<00:00,  2.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 258.14it/s]\n",
      "100%|███████████████████████████████████████████████████████| 924621/924621 [25:52<00:00, 595.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_preprocess_data(cat_feats):\n",
    "    train = pd.read_parquet('../src/data/raw/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    \n",
    "    cat_features = cat_feats.copy()\n",
    "    \n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    \n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    for col in train_num_agg:\n",
    "        for col_2 in ['first', 'mean', 'std', 'min', 'max']:\n",
    "            if 'last' in col and col.replace('last', col_2) in train_num_agg:\n",
    "                train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', col_2)]\n",
    "                train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', col_2)]\n",
    "    \n",
    "    train_labels = pd.read_csv('../src/data/raw/train_labels.csv')\n",
    "    \n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    \n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del train_cat_agg, train_num_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    train = train.merge(train_diff, how = 'inner', on = 'customer_ID')\n",
    "    del train_diff\n",
    "    gc.collect()\n",
    "    \n",
    "    train = train.merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_labels\n",
    "    gc.collect()\n",
    "    \n",
    "    train.to_parquet('../src/data/processed/train_fe_loaded.parquet')\n",
    "    del train\n",
    "    gc.collect()\n",
    "    \n",
    "    test = pd.read_parquet('../src/data/raw/test.parquet')\n",
    "    \n",
    "    print('Starting test feature engineer...')\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    for col in test_num_agg:\n",
    "        for col_2 in ['first', 'mean', 'std', 'min', 'max']:\n",
    "            if 'last' in col and col.replace('last', col_2) in test_num_agg:\n",
    "                test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', col_2)]\n",
    "                test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', col_2)]\n",
    "    \n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    \n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    \n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    \n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg\n",
    "    gc.collect()    \n",
    "    test = test.merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_diff\n",
    "    gc.collect()    \n",
    "    test.to_parquet('../src/data/processed/test_fe_loaded.parquet')\n",
    "    \n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: ../src/data/processed/dataset-metadata.json\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p ../src/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file test_fe_loaded.parquet\n",
      "100%|██████████████████████████████████████| 2.76G/2.76G [01:10<00:00, 41.7MB/s]\n",
      "Upload successful: test_fe_loaded.parquet (3GB)\n",
      "Starting upload for file train_fe_loaded.parquet\n",
      "100%|██████████████████████████████████████| 1.53G/1.53G [00:42<00:00, 38.9MB/s]\n",
      "Upload successful: train_fe_loaded.parquet (2GB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/tarique7/amex-fe-addcats\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -p ../src/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
