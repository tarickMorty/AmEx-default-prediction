{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.379396Z",
     "iopub.status.busy": "2022-08-07T06:08:55.378107Z",
     "iopub.status.idle": "2022-08-07T06:08:55.412431Z",
     "shell.execute_reply": "2022-08-07T06:08:55.411149Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.379267Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.415365Z",
     "iopub.status.busy": "2022-08-07T06:08:55.414595Z",
     "iopub.status.idle": "2022-08-07T06:08:58.401412Z",
     "shell.execute_reply": "2022-08-07T06:08:58.399724Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.415313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "import math as mt\n",
    "from math import *\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "import itertools\n",
    "import scipy as sp\n",
    "\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    input_dir = '../src/data/processed/'\n",
    "    dpv = 'v4'\n",
    "    mv = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_v4.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_v4.parquet')\n",
    "    return train, test\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def amex_metric_np(preds, target):\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 2446), (924621, 2445))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "df_train, df_test = read_data()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.462180Z",
     "iopub.status.busy": "2022-08-07T06:08:58.461074Z",
     "iopub.status.idle": "2022-08-07T06:08:58.492634Z",
     "shell.execute_reply": "2022-08-07T06:08:58.491357Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.462119Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n",
    "cat_features = []\n",
    "for col in cat_cols:\n",
    "    for i in range(1, 14):\n",
    "        cat_features.append(col+'_'+('{:0>2}'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['customer_ID'], axis=1)\n",
    "X_test = df_test.drop(['customer_ID'], axis=1)\n",
    "Y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['B_38_02'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['B_38_02'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['B_30_02'] = np.where(X_test['B_30_02']==-1, 0, X_test['B_30_02'])\n",
    "X_test['B_38_02'] = np.where(X_test['B_38_02']==-1, 2, X_test['B_38_02'])\n",
    "\n",
    "# Label encode categorical features\n",
    "# for cat_col in tqdm(cat_features):\n",
    "#     encoder = LabelEncoder()    \n",
    "#     X_train[cat_col] = encoder.fit_transform(X_train[cat_col])\n",
    "#     X_test[cat_col] = encoder.transform(X_test[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0:-\n",
      "X_train shape: (367130, 2444)\n",
      "X_valid shape: (91783, 2444)\n",
      "X_test shape: (924621, 2444)\n",
      "Our fold 0 CV score is 0.7928680464958229\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1:-\n",
      "X_train shape: (367130, 2444)\n",
      "X_valid shape: (91783, 2444)\n",
      "X_test shape: (924621, 2444)\n",
      "[500]\ttraining's binary_logloss: 0.347133\ttraining's amex_metric: 0.760543\tvalid_1's binary_logloss: 0.350417\tvalid_1's amex_metric: 0.742846\n",
      "[1000]\ttraining's binary_logloss: 0.256225\ttraining's amex_metric: 0.780681\tvalid_1's binary_logloss: 0.263792\tvalid_1's amex_metric: 0.757842\n",
      "[1500]\ttraining's binary_logloss: 0.231022\ttraining's amex_metric: 0.796553\tvalid_1's binary_logloss: 0.242829\tvalid_1's amex_metric: 0.767007\n",
      "[2000]\ttraining's binary_logloss: 0.216061\ttraining's amex_metric: 0.811688\tvalid_1's binary_logloss: 0.233098\tvalid_1's amex_metric: 0.773669\n",
      "[2500]\ttraining's binary_logloss: 0.208394\ttraining's amex_metric: 0.823211\tvalid_1's binary_logloss: 0.229898\tvalid_1's amex_metric: 0.776363\n",
      "[3000]\ttraining's binary_logloss: 0.200862\ttraining's amex_metric: 0.833447\tvalid_1's binary_logloss: 0.227318\tvalid_1's amex_metric: 0.778302\n",
      "[3500]\ttraining's binary_logloss: 0.19394\ttraining's amex_metric: 0.844415\tvalid_1's binary_logloss: 0.225488\tvalid_1's amex_metric: 0.780748\n",
      "[4000]\ttraining's binary_logloss: 0.187981\ttraining's amex_metric: 0.854275\tvalid_1's binary_logloss: 0.224428\tvalid_1's amex_metric: 0.781952\n",
      "[4500]\ttraining's binary_logloss: 0.18218\ttraining's amex_metric: 0.864093\tvalid_1's binary_logloss: 0.223607\tvalid_1's amex_metric: 0.782758\n",
      "[5000]\ttraining's binary_logloss: 0.176441\ttraining's amex_metric: 0.873835\tvalid_1's binary_logloss: 0.222933\tvalid_1's amex_metric: 0.782697\n",
      "[5500]\ttraining's binary_logloss: 0.171334\ttraining's amex_metric: 0.88254\tvalid_1's binary_logloss: 0.222438\tvalid_1's amex_metric: 0.783293\n",
      "[6000]\ttraining's binary_logloss: 0.167013\ttraining's amex_metric: 0.890991\tvalid_1's binary_logloss: 0.222186\tvalid_1's amex_metric: 0.782979\n",
      "[6500]\ttraining's binary_logloss: 0.16247\ttraining's amex_metric: 0.898448\tvalid_1's binary_logloss: 0.22185\tvalid_1's amex_metric: 0.78291\n",
      "[7000]\ttraining's binary_logloss: 0.157248\ttraining's amex_metric: 0.906822\tvalid_1's binary_logloss: 0.221474\tvalid_1's amex_metric: 0.783759\n",
      "[7500]\ttraining's binary_logloss: 0.152292\ttraining's amex_metric: 0.91459\tvalid_1's binary_logloss: 0.221218\tvalid_1's amex_metric: 0.783832\n",
      "Our fold 1 CV score is 0.7838317039591218\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2:-\n",
      "X_train shape: (367130, 2444)\n",
      "X_valid shape: (91783, 2444)\n",
      "X_test shape: (924621, 2444)\n",
      "[500]\ttraining's binary_logloss: 0.346982\ttraining's amex_metric: 0.75907\tvalid_1's binary_logloss: 0.350557\tvalid_1's amex_metric: 0.748091\n",
      "[1000]\ttraining's binary_logloss: 0.256145\ttraining's amex_metric: 0.779457\tvalid_1's binary_logloss: 0.263955\tvalid_1's amex_metric: 0.761488\n",
      "[1500]\ttraining's binary_logloss: 0.230923\ttraining's amex_metric: 0.795531\tvalid_1's binary_logloss: 0.242847\tvalid_1's amex_metric: 0.770694\n",
      "[2000]\ttraining's binary_logloss: 0.216025\ttraining's amex_metric: 0.810502\tvalid_1's binary_logloss: 0.233026\tvalid_1's amex_metric: 0.776118\n",
      "[2500]\ttraining's binary_logloss: 0.20838\ttraining's amex_metric: 0.821772\tvalid_1's binary_logloss: 0.229493\tvalid_1's amex_metric: 0.779513\n",
      "[3000]\ttraining's binary_logloss: 0.200851\ttraining's amex_metric: 0.83325\tvalid_1's binary_logloss: 0.226755\tvalid_1's amex_metric: 0.782824\n",
      "[3500]\ttraining's binary_logloss: 0.194053\ttraining's amex_metric: 0.844176\tvalid_1's binary_logloss: 0.225025\tvalid_1's amex_metric: 0.784159\n",
      "[4000]\ttraining's binary_logloss: 0.188072\ttraining's amex_metric: 0.854818\tvalid_1's binary_logloss: 0.223926\tvalid_1's amex_metric: 0.785742\n",
      "[4500]\ttraining's binary_logloss: 0.182235\ttraining's amex_metric: 0.864732\tvalid_1's binary_logloss: 0.222991\tvalid_1's amex_metric: 0.786535\n",
      "[5000]\ttraining's binary_logloss: 0.176507\ttraining's amex_metric: 0.874108\tvalid_1's binary_logloss: 0.222221\tvalid_1's amex_metric: 0.787195\n",
      "[5500]\ttraining's binary_logloss: 0.171444\ttraining's amex_metric: 0.882986\tvalid_1's binary_logloss: 0.221766\tvalid_1's amex_metric: 0.787609\n",
      "[6000]\ttraining's binary_logloss: 0.16713\ttraining's amex_metric: 0.891057\tvalid_1's binary_logloss: 0.221448\tvalid_1's amex_metric: 0.788637\n",
      "[6500]\ttraining's binary_logloss: 0.16255\ttraining's amex_metric: 0.898913\tvalid_1's binary_logloss: 0.221158\tvalid_1's amex_metric: 0.789385\n",
      "[7000]\ttraining's binary_logloss: 0.157302\ttraining's amex_metric: 0.907399\tvalid_1's binary_logloss: 0.220813\tvalid_1's amex_metric: 0.789229\n",
      "[7500]\ttraining's binary_logloss: 0.152354\ttraining's amex_metric: 0.915526\tvalid_1's binary_logloss: 0.220542\tvalid_1's amex_metric: 0.790398\n",
      "Our fold 2 CV score is 0.7903981339269848\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3:-\n",
      "X_train shape: (367131, 2444)\n",
      "X_valid shape: (91782, 2444)\n",
      "X_test shape: (924621, 2444)\n",
      "[500]\ttraining's binary_logloss: 0.346707\ttraining's amex_metric: 0.760215\tvalid_1's binary_logloss: 0.351518\tvalid_1's amex_metric: 0.742896\n",
      "[1000]\ttraining's binary_logloss: 0.255652\ttraining's amex_metric: 0.781226\tvalid_1's binary_logloss: 0.265274\tvalid_1's amex_metric: 0.756077\n",
      "[1500]\ttraining's binary_logloss: 0.230462\ttraining's amex_metric: 0.797791\tvalid_1's binary_logloss: 0.244406\tvalid_1's amex_metric: 0.764515\n",
      "[2000]\ttraining's binary_logloss: 0.215641\ttraining's amex_metric: 0.812202\tvalid_1's binary_logloss: 0.234663\tvalid_1's amex_metric: 0.770912\n",
      "[2500]\ttraining's binary_logloss: 0.208006\ttraining's amex_metric: 0.824023\tvalid_1's binary_logloss: 0.231192\tvalid_1's amex_metric: 0.774618\n",
      "[3000]\ttraining's binary_logloss: 0.200428\ttraining's amex_metric: 0.83469\tvalid_1's binary_logloss: 0.228449\tvalid_1's amex_metric: 0.775603\n",
      "[3500]\ttraining's binary_logloss: 0.193549\ttraining's amex_metric: 0.8456\tvalid_1's binary_logloss: 0.226613\tvalid_1's amex_metric: 0.777661\n",
      "[4000]\ttraining's binary_logloss: 0.187561\ttraining's amex_metric: 0.855504\tvalid_1's binary_logloss: 0.225487\tvalid_1's amex_metric: 0.77875\n",
      "[4500]\ttraining's binary_logloss: 0.181744\ttraining's amex_metric: 0.865271\tvalid_1's binary_logloss: 0.224688\tvalid_1's amex_metric: 0.779567\n",
      "[5000]\ttraining's binary_logloss: 0.176032\ttraining's amex_metric: 0.874765\tvalid_1's binary_logloss: 0.223944\tvalid_1's amex_metric: 0.780151\n",
      "[5500]\ttraining's binary_logloss: 0.170951\ttraining's amex_metric: 0.883719\tvalid_1's binary_logloss: 0.223416\tvalid_1's amex_metric: 0.780662\n",
      "[6000]\ttraining's binary_logloss: 0.166639\ttraining's amex_metric: 0.891281\tvalid_1's binary_logloss: 0.22319\tvalid_1's amex_metric: 0.78111\n",
      "[6500]\ttraining's binary_logloss: 0.162097\ttraining's amex_metric: 0.899176\tvalid_1's binary_logloss: 0.223011\tvalid_1's amex_metric: 0.780602\n",
      "[7000]\ttraining's binary_logloss: 0.156831\ttraining's amex_metric: 0.907149\tvalid_1's binary_logloss: 0.222616\tvalid_1's amex_metric: 0.780932\n",
      "[7500]\ttraining's binary_logloss: 0.151868\ttraining's amex_metric: 0.915756\tvalid_1's binary_logloss: 0.222359\tvalid_1's amex_metric: 0.781953\n",
      "Our fold 3 CV score is 0.7819526952397391\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4:-\n",
      "X_train shape: (367131, 2444)\n",
      "X_valid shape: (91782, 2444)\n",
      "X_test shape: (924621, 2444)\n",
      "[500]\ttraining's binary_logloss: 0.34718\ttraining's amex_metric: 0.759429\tvalid_1's binary_logloss: 0.350402\tvalid_1's amex_metric: 0.747839\n",
      "[1000]\ttraining's binary_logloss: 0.256385\ttraining's amex_metric: 0.779897\tvalid_1's binary_logloss: 0.263297\tvalid_1's amex_metric: 0.761087\n",
      "[1500]\ttraining's binary_logloss: 0.231293\ttraining's amex_metric: 0.795495\tvalid_1's binary_logloss: 0.24212\tvalid_1's amex_metric: 0.769706\n",
      "[2000]\ttraining's binary_logloss: 0.216433\ttraining's amex_metric: 0.810364\tvalid_1's binary_logloss: 0.232021\tvalid_1's amex_metric: 0.776378\n",
      "[2500]\ttraining's binary_logloss: 0.208852\ttraining's amex_metric: 0.821938\tvalid_1's binary_logloss: 0.228456\tvalid_1's amex_metric: 0.780148\n",
      "[3000]\ttraining's binary_logloss: 0.201309\ttraining's amex_metric: 0.832566\tvalid_1's binary_logloss: 0.225513\tvalid_1's amex_metric: 0.782894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500]\ttraining's binary_logloss: 0.194398\ttraining's amex_metric: 0.84343\tvalid_1's binary_logloss: 0.223495\tvalid_1's amex_metric: 0.784861\n",
      "[4000]\ttraining's binary_logloss: 0.188423\ttraining's amex_metric: 0.852925\tvalid_1's binary_logloss: 0.222364\tvalid_1's amex_metric: 0.786692\n",
      "[4500]\ttraining's binary_logloss: 0.182605\ttraining's amex_metric: 0.862625\tvalid_1's binary_logloss: 0.221464\tvalid_1's amex_metric: 0.788072\n",
      "[5000]\ttraining's binary_logloss: 0.176888\ttraining's amex_metric: 0.872399\tvalid_1's binary_logloss: 0.220728\tvalid_1's amex_metric: 0.78828\n",
      "[5500]\ttraining's binary_logloss: 0.171831\ttraining's amex_metric: 0.881393\tvalid_1's binary_logloss: 0.220313\tvalid_1's amex_metric: 0.788633\n",
      "[6000]\ttraining's binary_logloss: 0.167496\ttraining's amex_metric: 0.889388\tvalid_1's binary_logloss: 0.219989\tvalid_1's amex_metric: 0.788517\n",
      "[6500]\ttraining's binary_logloss: 0.162927\ttraining's amex_metric: 0.897436\tvalid_1's binary_logloss: 0.219721\tvalid_1's amex_metric: 0.788713\n",
      "[7000]\ttraining's binary_logloss: 0.157681\ttraining's amex_metric: 0.905719\tvalid_1's binary_logloss: 0.219362\tvalid_1's amex_metric: 0.788498\n",
      "[7500]\ttraining's binary_logloss: 0.152687\ttraining's amex_metric: 0.914208\tvalid_1's binary_logloss: 0.219095\tvalid_1's amex_metric: 0.788704\n",
      "Our fold 4 CV score is 0.788704248337184\n"
     ]
    }
   ],
   "source": [
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'dart',\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'verbose': -1,\n",
    "    }\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(X_train, Y_train)):\n",
    "\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold}:-')\n",
    "    x_train, x_val = X_train.drop('target', axis=1).iloc[trn_ind], X_train.drop('target', axis=1).iloc[val_ind]\n",
    "    y_train, y_val = Y_train.iloc[trn_ind], Y_train.iloc[val_ind]\n",
    "\n",
    "    print('X_train shape:', x_train.shape)\n",
    "    print('X_valid shape:', x_val.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "\n",
    "#     lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#     lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "#     if fold<=4:\n",
    "    if fold>0:\n",
    "\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 7500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 500,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'../src/models/BinaryModels/lgb_{CFG.mv}_dp{CFG.dpv}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "\n",
    "    else:\n",
    "        with open(f'../src/models/BinaryModels/lgb_{CFG.mv}_dp{CFG.dpv}_fold{fold}_seed{CFG.seed}.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds CV score is 0.7874231500547724\n"
     ]
    }
   ],
   "source": [
    "# Compute out of folds metric\n",
    "score = amex_metric(Y_train, oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': df_train['customer_ID'], 'target': Y_train, 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'oof_{CFG.mv}_dp{CFG.dpv}{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': df_test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'lgb_{CFG.mv}_dp{CFG.dpv}{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 75.2M/75.2M [00:07<00:00, 10.5MB/s]\n",
      "Successfully submitted to American Express - Default Prediction"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c amex-default-prediction -f lgb_v1_dpv45fold_seed42.csv -m \"all pivoted \\\n",
    "2444 feats CV 7875\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
