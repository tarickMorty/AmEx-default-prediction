{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.379396Z",
     "iopub.status.busy": "2022-08-07T06:08:55.378107Z",
     "iopub.status.idle": "2022-08-07T06:08:55.412431Z",
     "shell.execute_reply": "2022-08-07T06:08:55.411149Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.379267Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:55.415365Z",
     "iopub.status.busy": "2022-08-07T06:08:55.414595Z",
     "iopub.status.idle": "2022-08-07T06:08:58.401412Z",
     "shell.execute_reply": "2022-08-07T06:08:58.399724Z",
     "shell.execute_reply.started": "2022-08-07T06:08:55.415313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math as mt\n",
    "from math import *\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "import itertools\n",
    "import scipy as sp\n",
    "\n",
    "from itertools import combinations\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.462180Z",
     "iopub.status.busy": "2022-08-07T06:08:58.461074Z",
     "iopub.status.idle": "2022-08-07T06:08:58.492634Z",
     "shell.execute_reply": "2022-08-07T06:08:58.491357Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.462119Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.524565Z",
     "iopub.status.busy": "2022-08-07T06:08:58.523745Z",
     "iopub.status.idle": "2022-08-07T06:08:58.532931Z",
     "shell.execute_reply": "2022-08-07T06:08:58.531747Z",
     "shell.execute_reply.started": "2022-08-07T06:08:58.524529Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T06:08:58.536493Z",
     "iopub.status.busy": "2022-08-07T06:08:58.535785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 345/345 [01:31<00:00,  3.76it/s]\n",
      "100%|██████████████████████████████████████████| 33/33 [00:00<00:00, 505.52it/s]\n",
      "100%|██████████████████████████████████| 458913/458913 [12:32<00:00, 609.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 345/345 [03:02<00:00,  1.89it/s]\n",
      "100%|██████████████████████████████████████████| 33/33 [00:00<00:00, 310.16it/s]\n",
      "100%|██████████████████████████████████| 924621/924621 [25:45<00:00, 598.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_preprocess_data(cat_feats):\n",
    "    train = pd.read_parquet('../src/data/raw/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    \n",
    "    cat_features = cat_feats.copy()\n",
    "#     cat_feats_super = cat_features.copy()\n",
    "    \n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique', 'median'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    for col in cat_features:\n",
    "        train_cat_agg[col+'_median'] = train_cat_agg[col+'_median'].astype(int)\n",
    "        \n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    \n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    for feat in num_features:\n",
    "        train_num_agg[feat+'_isFirstEqMin'] = np.where(train_num_agg[feat+'_first']==train_num_agg[feat+'_min'], 1, 0).astype(int)\n",
    "        train_num_agg[feat+'_isFirstEqMax'] = np.where(train_num_agg[feat+'_first']==train_num_agg[feat+'_max'], 1, 0).astype(int)\n",
    "        train_num_agg[feat+'_isLastEqMin'] = np.where(train_num_agg[feat+'_last']==train_num_agg[feat+'_min'], 1, 0).astype(int)\n",
    "        train_num_agg[feat+'_isLastEqMax'] = np.where(train_num_agg[feat+'_last']==train_num_agg[feat+'_max'], 1, 0).astype(int)\n",
    "#         cat_feats_super.extend([feat+'_isFirstEqMin',feat+'_isFirstEqMax',feat+'_isLastEqMin',feat+'_isLastEqMax'])\n",
    "        \n",
    "    # Lag Features\n",
    "    for col in train_num_agg:\n",
    "        for col_2 in ['first', 'mean', 'std', 'min', 'max']:\n",
    "            if 'last' in col and col.replace('last', col_2) in train_num_agg:\n",
    "                train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', col_2)]\n",
    "                train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', col_2)]\n",
    "    \n",
    "    train_labels = pd.read_csv('../src/data/raw/train_labels.csv')\n",
    "    \n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    \n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    \n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del train_cat_agg, train_num_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    train = train.merge(train_diff, how = 'inner', on = 'customer_ID')\n",
    "    del train_diff\n",
    "    gc.collect()\n",
    "    \n",
    "    train = train.merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_labels\n",
    "    gc.collect()\n",
    "    \n",
    "    train.to_parquet('../src/data/processed/train_fe_public.parquet')\n",
    "    del train\n",
    "    gc.collect()\n",
    "    \n",
    "    test = pd.read_parquet('../src/data/raw/test.parquet')\n",
    "    \n",
    "    print('Starting test feature engineer...')\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique','median'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    for col in cat_features:\n",
    "        test_cat_agg[col+'_median'] = test_cat_agg[col+'_median'].astype(int)\n",
    "    \n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    for feat in num_features:\n",
    "        test_num_agg[feat+'_isFirstEqMin'] = np.where(test_num_agg[feat+'_first']==test_num_agg[feat+'_min'], 1, 0).astype(int)\n",
    "        test_num_agg[feat+'_isFirstEqMax'] = np.where(test_num_agg[feat+'_first']==test_num_agg[feat+'_max'], 1, 0).astype(int)\n",
    "        test_num_agg[feat+'_isLastEqMin'] = np.where(test_num_agg[feat+'_last']==test_num_agg[feat+'_min'], 1, 0).astype(int)\n",
    "        test_num_agg[feat+'_isLastEqMax'] = np.where(test_num_agg[feat+'_last']==test_num_agg[feat+'_max'], 1, 0).astype(int)\n",
    "    \n",
    "    # Lag Features\n",
    "    for col in test_num_agg:\n",
    "        for col_2 in ['first', 'mean', 'std', 'min', 'max']:\n",
    "            if 'last' in col and col.replace('last', col_2) in test_num_agg:\n",
    "                test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', col_2)]\n",
    "                test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', col_2)]\n",
    "    \n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    \n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    \n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg\n",
    "    gc.collect()    \n",
    "    test = test.merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_diff\n",
    "    gc.collect()    \n",
    "    test.to_parquet('../src/data/processed/test_fe_public.parquet')\n",
    "    \n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data(cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets init -p ../src/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets create -p ../src/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
