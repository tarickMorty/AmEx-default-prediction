{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 522/522 [03:24<00:00,  2.56it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 467.25it/s]\n",
      "100%|██████████████████████████████████| 458913/458913 [12:48<00:00, 596.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2539)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_parquet('../src/data/raw/train.parquet')\n",
    "features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]\n",
    "\n",
    "num_features = [col for col in features if col not in cat_features]\n",
    "print('Starting training feature engineer...')\n",
    "train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last','quantile'])\n",
    "train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "train_num_agg.reset_index(inplace = True)\n",
    "\n",
    "# Lag Features\n",
    "for col in train_num_agg:\n",
    "    if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
    "        train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
    "        train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "train_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "train_labels = pd.read_csv('../src/data/raw/train_labels.csv')\n",
    "# Transform float64 columns to float32\n",
    "cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "for col in tqdm(cols):\n",
    "    train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "\n",
    "# Transform int64 columns to int32\n",
    "cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "for col in tqdm(cols):\n",
    "    train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "# Get the difference\n",
    "train_diff = get_difference(train, num_features)\n",
    "train1 = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "# train1 = train_num_agg.merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "del train_num_agg, train_cat_agg, train_diff\n",
    "gc.collect()\n",
    "num_features.append('customer_ID')\n",
    "cat_features.append('customer_ID')\n",
    "train_num_agg = train[num_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg(['mean', 'min', 'max', 'quantile'])\n",
    "train_num_agg.columns = ['_L3M'.join(x) for x in train_num_agg.columns]\n",
    "train_num_agg.reset_index(inplace = True)\n",
    "train_cat_agg = train[cat_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg([ 'min', 'max'])\n",
    "train_cat_agg.columns = ['_L3M'.join(x) for x in train_cat_agg.columns]\n",
    "train_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "num_features.remove('customer_ID')\n",
    "cat_features.remove('customer_ID')\n",
    "train2 = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "del train_num_agg, train_cat_agg\n",
    "train = train1.merge(train2, how = 'left', on = 'customer_ID')\n",
    "gc.collect()\n",
    "\n",
    "train_cat_enc=pd.read_parquet('../src/data/processed/train_cat_enc_5fold_seed42.parquet')\n",
    "train=train.merge(train_cat_enc, how='left',on='customer_ID')\n",
    "print(train.shape)\n",
    "train.to_parquet('../src/data/processed/train_fe_rich.parquet')\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4f8dcn7YTy0J",
    "outputId": "fe190fb3-7421-40ce-904c-36f94b757f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test feature engineer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 522/522 [06:25<00:00,  1.35it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 257.07it/s]\n",
      "100%|██████████████████████████████████| 924621/924621 [26:34<00:00, 580.05it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../src/data/processed/test_cat_enc_5fold_seed42.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31455/4120898581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Save files to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtest_cat_enc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../src/data/processed/test_cat_enc_5fold_seed42.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cat_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customer_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/driverlessai-tutorials/TTA/scoring-pipeline/env/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[1;32m    458\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     )\n",
      "\u001b[0;32m~/driverlessai-tutorials/TTA/scoring-pipeline/env/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 )\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/driverlessai-tutorials/TTA/scoring-pipeline/env/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpath_or_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/driverlessai-tutorials/TTA/scoring-pipeline/env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../src/data/processed/test_cat_enc_5fold_seed42.parquet'"
     ]
    }
   ],
   "source": [
    "# Test FE\n",
    "test = pd.read_parquet('../src/data/raw/test.parquet')\n",
    "print('Starting test feature engineer...')\n",
    "test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last','quantile'])\n",
    "test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "# Lag Features\n",
    "for col in test_num_agg:\n",
    "    if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
    "        test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
    "        test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "test_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "# Transform float64 columns to float32\n",
    "cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "for col in tqdm(cols):\n",
    "    test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "# Transform int64 columns to int32\n",
    "cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "for col in tqdm(cols):\n",
    "    test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "# Get the difference\n",
    "test_diff = get_difference(test, num_features)\n",
    "test1 = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "# test1 = test_num_agg.merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "del test_num_agg, test_cat_agg, test_diff\n",
    "gc.collect()\n",
    "\n",
    "num_features.append('customer_ID')\n",
    "cat_features.append('customer_ID')\n",
    "test_num_agg = test[num_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg(['mean', 'min', 'max', 'quantile'])\n",
    "test_num_agg.columns = ['_L3M'.join(x) for x in test_num_agg.columns]\n",
    "test_num_agg.reset_index(inplace = True)\n",
    "test_cat_agg = test[cat_features].groupby(\"customer_ID\").tail(3).groupby(\"customer_ID\").agg([ 'min', 'max'])\n",
    "test_cat_agg.columns = ['_L3M'.join(x) for x in test_cat_agg.columns]\n",
    "test_cat_agg.reset_index(inplace = True)\n",
    "\n",
    "num_features.remove('customer_ID')\n",
    "cat_features.remove('customer_ID')\n",
    "test2 = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "del test_num_agg, test_cat_agg\n",
    "test = test1.merge(test2, how = 'left', on = 'customer_ID')\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zf-fFsyIaEWX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924621, 2538)\n"
     ]
    }
   ],
   "source": [
    "# Save files to disk\n",
    "test_cat_enc=pd.read_parquet('../src/data/processed/test_cat_enc_5fold_seed42.parquet')\n",
    "test=test.merge(test_cat_enc,how='left',on='customer_ID')\n",
    "\n",
    "print(test.shape)\n",
    "test.to_parquet('../src/data/processed/test_fe_rich.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2535)\n"
     ]
    }
   ],
   "source": [
    "f = ['pred_fm10_0', 'pred_fm10_1', 'pred_fm10_2', 'pred_fm10_3','customer_ID']\n",
    "train = pd.read_parquet('../src/data/processed/train_fe_rich.parquet')\n",
    "train = train.drop(['pred_fm10_0', 'pred_fm10_1', 'pred_fm10_2', 'pred_fm10_3'], axis=1)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2535)\n"
     ]
    }
   ],
   "source": [
    "train_cat_enc = pd.read_parquet('../src/data/processed/train_cat_enc_5fold_seed42.parquet')\n",
    "train = train.merge(train_cat_enc, how='left', on='customer_ID')\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2539)\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train, train_cat_enc[['pred_fm10_0', 'pred_fm10_1', 'pred_fm10_2', 'pred_fm10_3']]], axis=1)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('../src/data/processed/train_fe_rich.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Revised_iteration_0_8.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
